{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "Decision Tree can be applied to both regression and classification. \n",
    "\n",
    "It constitute ensemble method, such as random forest, Adaboost...\n",
    "\n",
    "In this chapter, I'll go over how to train, visualize, algorithm, and finally, how to regularize on this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training and Visualization\n",
    "\n",
    "##### with iris classificaiton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training (max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "You can get a visualized decision tree by code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(tree_clf, \n",
    "                out_file=\"iris_tree.dot\",\n",
    "                feature_names=iris.feature_names[2:],\n",
    "                class_names=iris.target_names,\n",
    "                rounded=True,\n",
    "                filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It classfy samples only by each nodes which is binary classifier.\n",
    "\n",
    "Like a twenty questions, It is quite easy to understand how to classify.\n",
    "\n",
    "All nodes, except leaf nodes(which doesn't have child nodes), have one question with one feature.(**Petal length < x**)\n",
    "\n",
    "And each nodes means a decision boundary(line) on the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction Probability \n",
    "\n",
    "In scikit-learn, It provides another value, prediction probability.\n",
    "\n",
    "Each samples has probability that belong specific class. (Setosa, Versicolor and Virginica.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.90740741, 0.09259259]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict_proba([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows each probability, according to final nodes, which a sample belong to. Its impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CART algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is called greedy algorithm, since it considers right next node's impurity to constuct a model.\n",
    "\n",
    "Left node's impurity and the others impurity(Give weight by number of samples). \n",
    "\n",
    "Repeated calculation of this algorithm constitute decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gini vs. Entropy ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikitlearn use **Gini impurity** as default, but Entropy also can be used.\n",
    "\n",
    "What's difference between gini and entropy?\n",
    "\n",
    "**There is not much difference.**\n",
    "\n",
    "But gini is a bit faster than entropy, and entropy makes more balanced trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many parameters to regularize decision tree model.\n",
    "\n",
    "##### max_depth: Limit depth of tree. (Default=None)\n",
    "\n",
    "##### min_samples_split: Minimum number of samples to split nodes.\n",
    "\n",
    "##### min_samples_leaf: Minimum number of samples that leaf nodes must have.\n",
    "\n",
    "##### max_leaf_nodes: Maximum number of leaf nodes.\n",
    "\n",
    "##### max_features: Maximum features to use for spliting each node.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
